Watch Demo :) https://drive.google.com/file/d/12iwXs2dyR4gu95AxzSWgLS1StC32xo44/view?usp=sharing

# ChatPDF ğŸ“šâ€“ Conversational PDF Reader Powered by RAG

ChatPDF is a scalable, full-stack application that allows users to interact with their PDF documents using natural language queries. Built by replicating a modern Retrieval-Augmented Generation (RAG) system as demonstrated in a popular tutorial, ChatPDF leverages cutting-edge technologies for seamless document understanding and querying.

## âœ¨ Features

- ğŸ“„ **PDF Upload & Chunking** â€“ Upload and automatically segment PDFs into chunks for efficient processing.
- ğŸ¤– **Smart Querying with LLMs** â€“ Use powerful language models to answer questions about your documents.
- ğŸ” **Semantic Search** â€“ Transform queries into vector embeddings to retrieve relevant context from uploaded files.
- âš™ï¸ **Scalable Architecture** â€“ Designed with asynchronous workflows and modular components.
- ğŸ” **Authentication with Clerk** â€“ Secure and user-friendly login system.
- ğŸ› ï¸ **Dockerized Deployment** â€“ Containerized setup for quick dev, test, and production workflows.
- âš¡ **Queue Management** â€“ Powered by BullMQ to handle background jobs and file processing.

## ğŸ§° Tech Stack

| Layer            | Technology       |
|------------------|------------------|
| Frontend         | Next.js, React   |
| Backend          | Node.js, Express |
| Authentication   | Clerk            |
| Vector Database  | Quadrant DB      |
| Queue System     | BullMQ           |
| Containerization | Docker           |

## ğŸ§  How It Works

1. **User uploads a PDF** via the Next.js frontend.
2. **Multer middleware** on the Express server handles the file.
3. **Document is split** into chunks and transformed into vector embeddings.
4. **Chunks are stored** in Quadrant DB for retrieval.
5. **User submits a query**, which is also embedded into a vector.
6. **Top relevant chunks are retrieved** based on vector similarity.
7. **Query + Context** are passed to an LLM (like GPT) for response generation.
8. **Response is shown** in the chat-like interface.

## ğŸ–¥ï¸ Getting Started

### ğŸ”§ Prerequisites

- Node.js
- Docker & Docker Compose
- OpenAI API Key
- Clerk credentials

### ğŸš€ Installation

```bash
# Clone the repository
git clone https://github.com/your-username/chatpdf.git
cd chatpdf

# Copy environment variables and update them
cp .env.example .env

# Start the app
docker-compose up --build
```

Open your browser and navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“ Environment Variables

Update your `.env` file with:

```env
CLERK_API_KEY=your-clerk-key
CLERK_FRONTEND_API=your-clerk-frontend-api
GEMINI_API_KEY=your-openai-api-key
HF_API_KEY=your-huggingface-api-key
VECTOR_DB_URL=your-quadrant-db-url
```

## ğŸ“Œ Project Highlights

- ğŸ§± **Modular Components**: Uploading, processing, querying â€“ all separated for better maintainability.
- ğŸŒ **UI/UX Best Practices**: Built-in wireframing considerations, utility classes, and conditional rendering.
- ğŸ§ª **Built for Scale**: Designed to handle high user loads using modern queue and container strategies.
- ğŸ§µ **Continuous Feedback Loop**: Designed with future feature improvements and user feedback in mind.

## ğŸ› ï¸ Future Plans

- âœ… Role-based access control
- ğŸ“Š Add usage dashboard
- ğŸŒ Internationalization (i18n)
- ğŸ§ª Integration tests with CI/CD

## ğŸ™Œ Acknowledgements

Inspired by [this video tutorial](#) on building scalable RAG systems. Big thanks to the creator for the step-by-step insights into real-world document AI applications.

---

**Made with â¤ï¸ using HuggingFace, Gemini, Clerk, Next.js, and Quadrant DB.**
